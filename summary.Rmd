---
title: "Covid19 Project"
author: "Team A"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:  
    rmdformats::readthedown:
      toc_float: true
      number_sections: true
      code_folding: hide
      keep_tex: yes
---



```{r setup, echo=FALSE, cache=FALSE}
  library(knitr)
library(rmdformats)
## Global options
options(max.print="75", scipen = 999, digits = 3, big.mark=",", warn = -1)
opts_chunk$set(echo=FALSE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

```{r basicfunct, include=FALSE}
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
```

```{r libraries}
#library(ggplot2)
#require(gridExtra)
#library(kableExtra)
loadPkg("ggplot2")
loadPkg("gridExtra")
loadPkg("kableExtra")
loadPkg("data.table") 
```

```{r xkablesummary}
loadPkg("xtable")
loadPkg("kableExtra")
loadPkg("stringi")

xkabledply = function(modelsmmrytable, title="Table", digits = 4, pos="left", bso="striped", wide=FALSE) { 
  #' Combining base::summary, xtable, and kableExtra, to easily display model summary. 
  #' wrapper for the base::summary function on model objects
  #' Can also use as head for better display
  #' ELo 202004 GWU DATS
  #' version 1.2
  #' @param modelsmmrytable This can be a generic table, a model object such as lm(), or the summary of a model object summary(lm()) 
  #' @param title Title of table. 
  #' @param digits Number of digits to display
  #' @param pos Position of table, c("left","center","right") 
  #' @param bso bootstrap_options = c("basic", "striped", "bordered", "hover", "condensed", "responsive")
  #' @param wide print table in long (FALSE) format or wide (TRUE) format
  #' @return HTML table for display
  #' @examples
  #' library("xtable")
  #' library("kableExtra")
  #' xkabledply( df, title="Table testing", pos="left", bso="hover" )
  #' xkabledply( ISLR::Hitters[1:5,] )
  if (wide) { modelsmmrytable <- t(modelsmmrytable) }
  modelsmmrytable %>%
    xtable() %>% 
    kable(caption = title, digits = digits) %>%
    kable_styling(bootstrap_options = bso, full_width = FALSE, position = pos)
}

xkabledplyhead = function(df, rows=5, title="Head", digits = 4, pos="left", bso="striped") { 
  xkabledply(df[1:rows, ], title, digits, pos, bso, wide=FALSE)
}

xkabledplytail = function(df, rows=5, title="Tail", digits = 4, pos="left", bso="striped") { 
  trows = nrow(df)
  xkabledply(df[ (trows-rows+1) : trows, ], title, digits, pos, bso, wide=FALSE)
}

xkablesummary = function(df, title="Table: Statistics summary.", digits = 4, pos="left", bso="striped") { 
  #' Combining base::summary, xtable, and kableExtra, to easily display numeric variable summary of dataframes. 
  #' ELo 202004 GWU DATS
  #' version 1.2
  #' @param df The dataframe.
  #' @param title Title of table. 
  #' @param digits Number of digits to display
  #' @param pos Position of table, c("left","center","right") 
  #' @param bso bootstrap_options = c("basic", "striped", "bordered", "hover", "condensed", "responsive")
  #' @return The HTML summary table for display, or for knitr to process into other formats 
  #' @examples
  #' xkablesummary( faraway::ozone )
  #' xkablesummary( ISLR::Hitters, title="Five number summary", pos="left", bso="hover"  )
  
  s = summary(df) %>%
    apply( 2, function(x) stringr::str_remove_all(x,c("Min.\\s*:\\s*","1st Qu.\\s*:\\s*","Median\\s*:\\s*","Mean\\s*:\\s*","3rd Qu.\\s*:\\s*","Max.\\s*:\\s*")) ) %>% # replace all leading words
    apply( 2, function(x) stringr::str_trim(x, "right")) # trim trailing spaces left
  
  colnames(s) <- stringr::str_trim(colnames(s))
  
  if ( dim(s)[1] ==6 ) { rownames(s) <- c('Min','Q1','Median','Mean','Q3','Max') 
  } else if ( dim(s)[1] ==7 ) { rownames(s) <- c('Min','Q1','Median','Mean','Q3','Max','NA') }
  
  xkabledply(s, title=title, digits = digits, pos=pos, bso=bso )
}

xkablevif = function(model, title="VIFs of the model", digits = 3, pos="left", bso="striped", wide=TRUE) { 
  #' Combining faraway::vif, xtable, and kableExtra, to easily display numeric summary of VIFs for a model. 
  #' ELo 202004 GWU DATS
  #' version 1.2
  #' @param model The lm or compatible model object.
  #' @param title Title of table. 
  #' @param digits Number of digits to display
  #' @param pos Position of table, c("left","center","right") 
  #' @param bso bootstrap_options = c("basic", "striped", "bordered", "hover", "condensed", "responsive")
  #' @param wide print table in long (FALSE) format or wide (TRUE) format
  #' @return The HTML summary table of the VIFs for a model for display, or for knitr to process into other formats 
  #' @examples
  #' xkablevif( lm(Salary~Hits+RBI, data=ISLR::Hitters), wide=T )
  
  vifs = table( names(model$coefficients)[2:length(model$coefficients)] ) # remove intercept to set column names
  vifs[] = faraway::vif(model) # set the values
  if (wide) { vifs <- t(vifs) }
  xkabledply( vifs, title=title, digits = digits, pos=pos, bso=bso )
}
```

```{r outlierKD2}
# Fix outliers
outlierKD2 <- function(df, var, rm=FALSE) { 
    #' Original outlierKD functino by By Klodian Dhana,
    #' https://www.r-bloggers.com/identify-describe-plot-and-remove-the-outliers-from-the-dataset/
    #' Modified to have third argument for removing outliers instead of interactive prompt, 
    #' and after removing outlier, original df will not be changed. The function returns a new df, 
    #' which can be saved as original df name if desired.
    #' Check outliers, and option to remove them, save as a new dataframe. 
    #' @param df The dataframe.
    #' @param var The variable in the dataframe to be checked for outliers
    #' @param rm Boolean. Whether to remove outliers or not.
    #' @return The dataframe with outliers replaced by NA if rm==TRUE, or df if nothing changed
    #' @examples
    #' outlierKD2(mydf, height, FALSE)
    #' mydf = outlierKD2(mydf, height, TRUE)
    #' mydfnew = outlierKD2(mydf, height, TRUE)
    dt = df # duplicate the dataframe for potential alteration
    var_name <- eval(substitute(var),eval(dt))
    na1 <- sum(is.na(var_name))
    m1 <- mean(var_name, na.rm = T)
    par(mfrow=c(2, 2), oma=c(0,0,3,0))
    boxplot(var_name, main="With outliers")
    hist(var_name, main="With outliers", xlab=NA, ylab=NA)
    outlier <- boxplot.stats(var_name)$out
    mo <- mean(outlier)
    var_name <- ifelse(var_name %in% outlier, NA, var_name)
    boxplot(var_name, main="Without outliers")
    hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
    title("Outlier Check", outer=TRUE)
    na2 <- sum(is.na(var_name))
    cat("Outliers identified:", na2 - na1, "\n")
    cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "\n")
    cat("Mean of the outliers:", round(mo, 2), "\n")
    m2 <- mean(var_name, na.rm = T)
    cat("Mean without removing outliers:", round(m1, 2), "\n")
    cat("Mean if we remove outliers:", round(m2, 2), "\n")
    
    # response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ")
    # if(response == "y" | response == "yes"){
    if(rm){
        dt[as.character(substitute(var))] <- invisible(var_name)
        #assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
        cat("Outliers successfully removed", "\n")
        return(invisible(dt))
    } else {
        cat("Nothing changed", "\n")
        return(invisible(df))
    }
}
# sample usage
# mlb2 = outlierKD2(mlb, weight, TRUE) # This will remove weight outliers, replace those values by NA, then save it as a new dataframe mlb2
# mlb = outlierKD2(mlb, weight, TRUE) # This will remove weight outliers, replace those values by NA, then REPLACE the dataframe mlb with the new one.
# outlierKD2(mlb, weight, FALSE) # This will NOT remove weight outliers, but it will show the charts with and without outliers nonetheless. 
# outlierKD2(mlb, weight) # same as above, as the last argument is optional, default = FALSE 
```



# How did your question change, if at all, after EDA?

At the beginning we asked a few questions, such as “which race is the majority of the sample? Are patient from a certain race?” In the EDA study, we deleted the last sentence. Because this is an overall study of the COVID-19 epidemic in different regions of the United States, not a study of individual individuals. We cannot determine the race of each confirmed individual.

We also deleted “which race has the most average death rate and total cases” The reason is the same as above, because we cannot determine the situation of each individual and cannot make statistics on this problem. We can only observe the correlation coefficients between total cases, death and different proportion of races based on the correlation coefficient graph. Therefore, we changed the question to “The proportion of which race is related to the number of confirmed cases and deaths”.

We added a few more questions, "Are the total cases related to age/gender/Poverty?" We first divided total cases into four levels, and then found that the average values of these variables at different levels are significantly different, so we determined they are related to total cases. 

We also set another question at the beginning, "Have there been any general trends among the health conditions?". Studies have shown that the correlation coefficient between health (such as sleep status, medical history of various diseases, smoking, obesity, etc.) and death is not large. Only the correlation coefficient between liver_total_death and death is relatively high.

We deleted the question "Are there any common underlying health conditions?" and changed it to "Does any disease relate to the death rate?".

# Based on EDA can you begin to sketch out an answer to your question?

```{r input_data}
library("readxl")
data <- read_excel("Counties_Dataset.xlsx")
#summary(data)
#str(data)
#names(data)[8:] <- c("total_cases","deaths")
cols <- c(1:2, 7:19, 56)
small_df=data[,cols]
names(small_df)[16] <- c("poor_health")
#Disease_data<-data[,c(1,2,7,8,47,50,53,55,60,61,65,71,72)]
#stay_at_home<-data[,c(1,2,5,7,78,79,80,81,82)]
#str(stay_at_home)
#Print out the first 5 and the last 3 rows of the dataframe.**  
#head(data, 5)
#tail(data, 3)

```

```{r remove_NAs}
#Print the number of NA values per each columns 
#colSums(is.na(data))
#Which col contains NA values? 
#colnames(data)[!complete.cases(t(data))]

#Drops rows containing missing values in any variable:
data_noNA = na.omit(small_df)
#str(data_noNA)
```

## United States COVID-19 Cases and Deaths by Provinces (Cities)


### What are the top 15 Provinces based on the number of cases?

The following bar chart shows the top 15 cities by number of Covid-19 cases. 

```{r top_10_cases, echo=F}
 library(ggplot2)
 library(dplyr)
  top_n(data_noNA, n=15, total_cases) %>%
          ggplot(., aes(x=reorder(Province, -total_cases), y=total_cases, color=Province, fill=Province)) +
  geom_bar(aes(y=total_cases), stat="identity") + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 1, size = 12, hjust = 1), 
        axis.text.y = element_text(vjust = 1, size = 12, hjust = 1), 
        panel.border = element_rect(colour = "black", fill=NA, size=1)) + 
  labs(title="Barchart of Top 15 Provinces (determined by number of Cases)", x="Province", y="Number of Cases")   
  
```

The above Bar chart shows the top 15 provinces determined by the number of cases. New York province is highest city with number of covid19 cases, the total number is over 100000, while the number of cases in other cities  is less than 30000. 


### What are the top 15 Provinces based on the number of deaths?

The following bar chart shows the top 15 cities by number of deaths. 

```{r top_15_deaths, echo=F}
 library(ggplot2)
 library(dplyr)
  top_n(data_noNA, n=15, deaths) %>%
          ggplot(., aes(x=reorder(Province, -deaths), y=deaths, color=Province, fill=Province)) +
  geom_bar(aes(y=deaths), stat="identity") + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 1, size = 12, hjust = 1), 
        axis.text.y = element_text(vjust = 1, size = 12, hjust = 1), 
        panel.border = element_rect(colour = "black", fill=NA, size=1)) + 
  labs(title="Barchart of Top 15 Provinces (determined by number of Deaths)", x="Province", y="Number of Deaths")   
  
```

The above Bar chart shows the top 15 provinces determined by the number of deaths. New York province is highest city with number of deaths around 8000, while the number of deaths in other cities  is less than 1000. 


### What are the top 15 States based on the number of Tests?

```{r testsPerState, echo=F}
testsPerState=distinct(data, State, Tests)
```
```{r top_10_test, echo=F}
 library(ggplot2)
 library(dplyr)
    top_n(testsPerState, n=15, Tests) %>%
          ggplot(., aes(x=reorder(State, -Tests), y=Tests, color=State, fill=State)) +
  geom_bar(aes(y=Tests), stat="identity") + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 1, size = 12, hjust = 1), 
        axis.text.y = element_text(vjust = 1, size = 12, hjust = 1), 
        panel.border = element_rect(colour = "black", fill=NA, size=1)) + 
  labs(title="Barchart of Top 15 States (determined by number of Tests)", x="State", y="Number of Tests")   
  
```

The above Bar chart shows the top 15 States determined by the number of tests. It can be clearly seen that the number of tests has been done in New York State is around 499,143 tests which is considered to be the highest among the other states. Furthermore, the number of test has been done in other states is less than 200k.



### What is the average cases for each State?

```{r rop avg cases, echo=F}
print(aggregate(total_cases~State,data=data_noNA,FUN=mean))
```
### What is the average deaths for each State?

```{r rop avg deaths, echo=F}
print(aggregate(deaths~State,data=data_noNA,FUN=mean))
```


### Which cities had the greatest % of population of people with poor health?

```{r poorhealth, echo=F}
loadPkg("dplyr")
data_noNAinpoorhealth = subset(data_noNA, poor_health != "NA")[,c(1,16)]
data_noNAinpoorhealth$poor_health=as.numeric(data_noNAinpoorhealth$poor_health)
#head(data_noNAinpoorhealth)
a=arrange(data_noNAinpoorhealth, desc(poor_health))
#head(a,10)
``` 

```{r cities_poor_health, echo=F}
 library(ggplot2)
 library(dplyr)
    top_n(data_noNAinpoorhealth, n=15, poor_health) %>%
          ggplot(., aes(x=reorder(Province, -poor_health), y=poor_health, color=Province, fill=Province)) +
  geom_bar(aes(y=poor_health), stat="identity") + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 1, size = 12, hjust = 1), 
        axis.text.y = element_text(vjust = 1, size = 12, hjust = 1), 
        panel.border = element_rect(colour = "black", fill=NA, size=1)) + 
  labs(title="Barchart of the top 15 cities had the greatest % of population of people with poor health", x="Province", y="Poor_health")   
  
```


## Patient Demographics
### What are the patient demographics?
```{r}
getwd()
df=data.frame(read.csv("V1.csv", header = TRUE))[,-c(25,26,27,28,29,30,31,32,33)]
#str(df)
colnames(df) <- c("TC","death","Population","young","old","black","AIAN","Asian","NH","Hispanic","NHW","Female","Rural","Population.Density","Housing.Density","Sunlight","GDP","Poverty","Unemployed","Children.Poverty","Income.Inequality","Social","PM2.5","Water","SHP")
df$Water=as.factor(df$Water)
df$Poverty=as.numeric(df$Poverty)
#str(df)

loadPkg("DMwR")
df2=centralImputation(df) #Fill in missing values
# sum(is.na(df2)) #Now there are no missing values

xkablesummary(df2[,c(1,3,4,5,6,7,8,9,10,11,12,18,22)])
```

From the average of the output results, we can see that the average proportion of teenagers under the age of 18 is 22.1%, and the average proportion of people over 65 is 19.3%. The largest number of all races is Non-Hispanic White, with an average proportion of 76.2. The average proportion of women is 49.9, the average proportion of the poor is 15.9%, and the average of the Social Association Rate is 11.6.
We divide the data into four levels according to total cases.

### Which race is the majority of the sample?
```{r}
racemean = data.frame(Race.ratio= c(8.8,2.4,1.5,0.1,9.6,76.2), legend= c('Black','American Indian & Alaska Native','Asian','Native Hawaiian/Other Pacific Islander','Hispanic','Non-Hispanic White'))
p = ggplot(racemean, aes(x = "", y =Race.ratio, fill =legend)) + 
  geom_bar(stat = "identity", width = 1) +  
  coord_polar(theta = "y")   
p
```
According to the average value, we get a pie chart of race proportions, from which we can see the overall proportions of different races.

## Stay at home policy in each province
### Is the stay at home policy related to the Total Cases infected?
First, we do the t-test and find the 80% and 99% confidence interval.
```{r,t-test,echo=F}
loadPkg("dplyr") 
#remove the outlier for total_cases
stay_at_home<-data[,c(1,2,5,7,78,79,80,81,82)]
names(stay_at_home)[5:9] <- c("first_case","stay_home","no_case","no_order","order_after_first")
stay_at_home$first_case<-as.factor(stay_at_home$first_case)
#bike$Season<-as.factor(bike$Season)
#colnames(stay_at_home)[8,9]=c("no_order","order_after_first")
#stay_at_home<-subset(stay_at_home,is.na(total_cases))
nrow(stay_at_home)
#str(stay_at_home)
#stay_at_home<-stay_at_home %>% subset(total_cases>0)
#nrow(stay_at_home)
#stay_at_home
stay_at_home = outlierKD2(stay_at_home, total_cases, TRUE)
nrow(stay_at_home)
Before_order <- subset(stay_at_home,no_order==1)
After_order  <- subset(stay_at_home,order_after_first==1)
Before_ttest80 = t.test(x = Before_order$total_cases, conf.level = 0.80)
Before_ttest80
After_ttest80 = t.test(x = After_order$total_cases, conf.level = 0.80)
After_ttest80
Before_ttest99 = t.test(x = Before_order$total_cases, conf.level = 0.99)
Before_ttest99
After_ttest99 = t.test(x = After_order$total_cases, conf.level = 0.99)
After_ttest99
```
Before first case have stay at home order 80% & 99% confidence interval is not overlap with after first case have stay at home order. As a result, the average Total Cases infected number is different from separate groups that the Stay at Home Policy is order before the First Case or not.

### Is the stay at home policy after the first case related to the people inflected number?
```{r,box_plot,echo=F}
ggplot(data = Before_order, aes(x=first_case, y=total_cases))+
  geom_boxplot(fill = "#0000aa", alpha = .7)+
  labs(title="Total Cases Boxplot for Before the  First Case Stay at Home") +
  labs(x="First Cases", y="Total Cases") 
ggplot(data = After_order, aes(x=first_case, y=total_cases))+
  geom_boxplot(fill="#FF9933", alpha = .7)+
  labs(title="Total Cases Boxplot for After the First Case Stay at Home") +
  labs(x="First Cases", y="Total Cases") 
#str(stay_at_home)
```

For these two box-plot diagoram, the Total Cases infected are more higher if the Stay at Home Policy is ordered After the first cases. So we can say the Stay at Home Policy do decrease the Totall Cases inflected if it is ordered before the Fist Case happened. 


## Underlying Health Conditions

### Does any disease relate to the death rate?

```{r,disease,echo=F}
loadPkg("dplyr") 
loadPkg("corrplot")
#str(disease)
disease<-data[,c(1,2,7,8,47,50,53,55,60,61,65,71,72)]
names(disease)[5:13] <- c("sleep_hour","diabetes","heart_disease","obesity_age","smokers",
"adult_obesity","excessive_drink","liver_crude_mortality","liver_Total_death","")
disease2<-disease[ , -which(colnames(disease) %in% c("Province","State","total_cases"))]

disease2$sleep_hour<-as.numeric(as.character(disease2$sleep_hour))
disease2$smokers<-as.numeric(as.character(disease2$smokers))
disease2$adult_obesity<-as.numeric(as.character(disease2$adult_obesity))
disease2$excessive_drink<-as.numeric(as.character(disease2$excessive_drink))
disease2$liver_crude_mortality<-as.numeric(as.character(disease2$liver_crude_mortality))
disease2$liver_Total_death<-as.numeric(as.character(disease2$liver_Total_death))
disease2=disease2 %>% subset(deaths>0)
#disease2=disease2 %>% subset(total_cases>0)
disease2=disease2 %>% subset(heart_disease>0)
disease2=disease2 %>% subset(obesity_age>0)
disease2=disease2 %>% subset(smokers>0)
disease2=disease2 %>% subset(diabetes>0)
disease2=disease2 %>% subset(sleep_hour>0)
disease2=disease2 %>% subset(adult_obesity>0)
disease2=disease2 %>% subset(excessive_drink>0)
disease2=disease2 %>% subset(liver_crude_mortality>0)
disease2=disease2 %>% subset(liver_Total_death>0)
disease2_corr<-cor(disease2)
#str(disease2)
corrplot(disease2_corr,method="circle")
#corrplot.mixed(cor(disease2))
#corrplot.mixed(cor(race))
```


It shows liver_total_death is highly correlated to deaths at correlation = 0.4338.

## Impact of Temperature

### Does the temperature relate the Total Cases or Death Rate? 

```{r,temperature,echo=F}
temp<-data[,c(1,2,6,7,8,75,76,77)]
names(temp)[3] <- c("days")
names(temp)[6:8] <- c("temp_peak","temp_before","temp_current")
str(temp)
#ggplot(data=temp)+
#  geom_point(mapping = aes(x=temp_peak, y=total_cases, color=State))+
#  ggtitle("Scatter plot of baseball player weigth(y, lbs) vs height(x, inches)")
temp2<-temp[ , -which(colnames(temp) %in% c("Province","State"))]
#temp2$liver_Total_death<-as.numeric(as.character(disease2$liver_Total_death))
temp2=temp2 %>% subset(deaths>0)
temp2=temp2 %>% subset(days>0)
temp2=temp2 %>% subset(total_cases>0)
temp2=temp2 %>% subset(temp_peak>0)
temp2=temp2 %>% subset(temp_before>0)
temp2=temp2 %>% subset(temp_current>0)
temp2_corr<-cor(temp2)
#str(disease2)
loadPkg("corrplot")
corrplot(temp2_corr,method="circle")
```

By the correlation diagorm, the temperature is less relate to total_cases and deaths. 

```{r}
#sum(is.na(df2$TC))
break1=fivenum(df2$TC)
break1
labels = c("0-2", "2-9", "9-39", "39-110465")
rank=cut(df2$TC,break1,labels,ordered_result = T)

```

## The proportion of which race is related to the number of confirmed cases and deaths
```{r}
race=subset(df2[,c(1,2,6,7,8,9,10,11)])
loadPkg("corrplot")
corrplot.mixed(cor(race))
```


The results show that the positive correlation coefficient between Asians and total cases is the largest, which is 0.19, indicating that there are more total cases where the proportion of Asians is high. Followed by Hispanics and blacks, but the correlation coefficients are very small. The correlation coefficient between non-Hispanic whites and TC is -0.1. the relationship between the number of deaths and race, and the results are consistent with the above results.

## Are the total cases related to age?
### Are the total cases related to the proportion of people over 65?
```{r boxplot old, echo=FALSE}
loadPkg("plotly")
ggplotly(ggplotly(ggplot(df2, aes(x=rank, y=old, fill=rank)) + geom_boxplot() + scale_fill_brewer(palette="Spectral") + ggtitle("Proportion of elderly over 65 vs. Total cases") + ylab("Proportion of elderly over 65") + xlab("Total cases") +  theme(plot.title= element_text(hjust=0.5, size = 14))))
```


It can be seen from the image that the proportion of elderly people is lower in areas with more total cases.

```{r old test}
loadPkg('lmtest')
test1 <- bptest(df2$old~rank)
test1$p.value

old.anova <- aov(df2$old~rank)
summary(old.anova)
TKcond <- TukeyHSD(old.anova)
TKcond

par(las=1)
plot(TukeyHSD(old.anova))
```

It shows that the proportion of elderly people over 65 years old is different in regions with different confirmed cases. The elderly have few outdoor activities and tend to live in large and sparsely populated areas, which is not conducive to the spread of the virus. Therefore, the epidemic situation is not serious in places with a high proportion of elderly people.

### Are the total cases related to the proportion of young people under 18?

```{r boxplot young, echo=FALSE}
ggplotly(ggplotly(ggplot(df2, aes(x=rank, y=young, fill=rank)) + geom_boxplot() + scale_fill_brewer(palette="Spectral") + ggtitle("proportion of youth under 18 vs. Total cases") + ylab("proportion of youth under 18") + xlab("Total cases") +  theme(plot.title= element_text(hjust=0.5, size = 14))))
```

It is difficult to see whether the two are related from the image.

```{r young bptest,echo=F}
test2 <- bptest(df2$young~rank)
test2$p.value
```

```{r young chitest}
break2=fivenum(df2$young)
break2
labels = c("0-20.1", "20.1-22.1", "22.1-23.8", "23.8-42.0")
youncate=cut(df2$young,break2,labels,ordered_result = T)

young_p <- table(rank, youncate)
x2test1 = chisq.test(young_p)
x2test1

```
The test indicates that there is a relationship between the two variables. The percentage of people under 18 will affect the total cases.

## Are the total cases related to gender?
```{r}
ggplotly(ggplotly(ggplot(df2, aes(x=rank, y=Female, fill=rank)) + geom_boxplot() + scale_fill_brewer(palette="Spectral") + ggtitle("Female vs. Total cases") + ylab("Proportion of female") + xlab("Total cases") +  theme(plot.title= element_text(hjust=0.5, size = 14))))
```

In areas with more total cases, the average percentage of women is higher.
```{r gender bptest}
test3 <- bptest(df2$Female~rank)
test3$p.value
```

```{r gender chitest}
break3=fivenum(df2$Female)
break3
labels = c("26.8-49.4", "49.4-50.3", "50.3-51.0", "51.0-56.9")
femalecate=cut(df2$Female,break3,labels,ordered_result = T)

female_p <- table(rank, femalecate)
x2test2 = chisq.test(female_p)
x2test2

```

From the results of the test, the proportion of female is related to total cases.

## Are the total cases related to Poverty?
```{r}
ggplotly(ggplotly(ggplot(df2, aes(x=rank, y=Poverty, fill=rank)) + geom_boxplot() + scale_fill_brewer(palette="Spectral") + ggtitle("Poverty vs. Total cases") + ylab("Proportion of Poverty") + xlab("Total cases") +  theme(plot.title= element_text(hjust=0.5, size = 14))))
```

From the first to the third level, the more total cases, the larger the average proportion of poor people. The average proportion of poor people in severely affected areas is the lowest.

```{r Poverty bptest}
test4 <- bptest(df2$Poverty~rank)
test4$p.value


Poverty.anova <- aov(df2$Poverty~rank)
summary(Poverty.anova)
TKcond <- TukeyHSD(Poverty.anova)
TKcond

par(las=1)
plot(TukeyHSD(Poverty.anova))
```


Places with a larger proportion of poor people have more TC. However, in regions with the most TC, the proportion of poor groups is the lowest. According to the previous research, we know that New York City is the place where the epidemic is the worst in the US. It may be because the prosperous cities are densely populated and the epidemic is serious, but the proportion of poor people in prosperous cities is not high.


# How did you select and determine the correct model to answer your question?

## Linear model
```{r}
getwd()
lineardf<-data[,c(1,2,7,8,9,10,11,12,13,14,15,16,17,19,20,21,22,23,24,26,33,34,35,37,39,41,47, 50,53,55,56,58,60,61,65,71,72)]
colnames(lineardf) <- c("Province","State","TC","deaths","population","young","old","black","AIAN","Asian","NH","Hispanic","NHW","Female","Rural","Population.Density","Housing.Density","Sunlight","GDP","Poverty","Unemployed","Children.Poverty","Income.Inequality","Social","PM2.5","SHP","sleep_hour","diabetes","heart_disease","obesity_age", "poorhealth","Unhealthy.Days","smokers","adult_obesity","excessive_drink","liver_crude_mortality","liver_Total_death")
#str(lineardf)
lineardf2=as.data.frame(lapply(lineardf,as.numeric))
#lineardf2$Water=as.factor(lineardf2$Water)
# subset(lassodf, TC != "NA")
lineardf3=na.omit(lineardf2[,-c(1,2,3)])
#str(lineardf3)

```

```{r,q10__,echo=F}
loadPkg("leaps")
reg.leaps1 <- regsubsets(deaths~., data = lineardf3, nbest = 1, method = "exhaustive")  # leaps, 
plot(reg.leaps1, scale = "bic", main = "BIC")
plot(reg.leaps1, scale = "adjr2", main = "Adjusted R^2")

lm.whole1<-lm(deaths~Population.Density+GDP+SHP+sleep_hour+poorhealth,data = lineardf3)
summary(lm.whole1)
faraway::vif(lm.whole1)

```

We use the regsubsets function, exhaustive method, to find the best model from two perspectives: BIC and adjusted R-squared. Both methods point to the same model, which contains five variables: Population Density per Square mile of Land, GDP (2018),% Severe Housing Problems, Sleep <7 Hours_Percent,% Fair or Poor Health. From the p-value, these five variables are all significant. VIF shows that these five variables have no high degree of autocorrelation and can be left in the model. The adjusted r-squared is 0.236, indicating that the model explained 23.6% of the variation in death.

Final model:
death=-41.185+0.002 Population.Density + 0.0000006479 GDP + 1.051 SHP +1.509 sleep_hour + -1.230 poorhealth


## LASSO Regression

Because there are many variables, Lasso regression is chosen to fit the best model. Lasso regression can change the coefficients of many variables to 0, which plays a role in variable selection.
```{r}
getwd()
lassodf=data.frame(read.csv("V1.csv", header = TRUE))[,-2]

colnames(lassodf) <- c("TC","population","young","old","black","AIAN","Asian","NH","Hispanic","NHW","Female","Rural","Population.Density","Housing.Density","Sunlight","GDP","Poverty","Unemployed","Children.Poverty","Income.Inequality","Social","PM2.5","Water","SHP","poorhealth","Unhealthy.Days","smokers","Obesity","Physically.ina","WAEO","CRD","Temp","Order")


lassodf$Poverty=as.numeric(lassodf$Poverty)
lassodf$Water=as.factor(lassodf$Water)
lassodf$Order=as.factor(lassodf$Order)
#str(lassodf)

# subset(lassodf, TC != "NA")
lassodf=na.omit(lassodf)

```

```{r uzscale_fcn}
uzscale <- function(df, append=0, excl=NULL) { 
  #' Standardize dataframe to z scores, safe for non-numeric variables. 
  #' ELo 201904 GWU DATS
  #' @param df The dataframe.
  #' @param append T/F or 0/1. Option to append scaled columns or replace original columns in the dataframe.
  #' @param excl A list c(a,b,"d","ef") of excluded columns, either by their indexes and/or names.
  #' @return The transformed dataframe, appended or replaced with standardized scores. Non-numeric columns will not be appended, or if "replace option" is chosen, the columns will be untouched.
  #' @examples
  #' library("ISLR")
  #' tmp = uzscale( Hitters )
  #' tmp = uzscale( Hitters, 1 )
  #' tmp = uzscale( Hitters, TRUE, c(19,"NewLeague") )
  
  append = ifelse(append==TRUE || append=="true" || append=="True" || append=="T" || append=="t" || append==1 || append=="1", TRUE, FALSE) # standardize append 
  nmax = length(df)
  if (nmax < 1 || !is.numeric(nmax) ) { return(df) }
  df1 = df
  onames = colnames(df)  # the original column names
  cnames = onames  # the new column names, if needed start with the original ones
  znames = paste("z",cnames, sep="")     # new column names added prefix 'z'. Those are non-numeric will not be used.
  nadd = ifelse(append, nmax, 0) # add to the column index or replace the orig columns
  j=1  # counting index
  for( i in 1:nmax ) {
    if ( is.numeric(df[,i]) && !( i %in% excl || onames[i] %in% excl ) ) { 
      df1[,j+nadd] = scale(df[,i])
      cnames = c(cnames, znames[i])
      j=j+1
    } else if ( !append ) { j=j+1
    } # if append == 1 and (colunm non-numeric or excluded), do not advance j.
  }
  if (append) { colnames(df1) <- cnames }
  return(df1)
}
```

```{r sd&split}
stdf=uzscale(lassodf, 0)

x=model.matrix(TC~.,stdf)[,-1]
y=stdf$TC

loadPkg("glmnet")
grid=10^seq(5,-5,length=100) # prepare log scale grid for λ values, from 10^10 to 10^-2, in 100 segments

loadPkg("dplyr")
set.seed(1)
train = stdf %>% sample_frac(0.5)
test = stdf %>% setdiff(train)

x_train = model.matrix(TC~., train)[,-1]
x_test = model.matrix(TC~., test)[,-1]

y_train = train %>% select(TC) %>% unlist() # %>% as.numeric()
y_test = test %>% select(TC) %>% unlist() # %>% as.numeric()
```

```{r lassomodel}
lasso.mod=glmnet(x_train,y_train,alpha=1,lambda=grid)
plot(lasso.mod)
set.seed(1)
cv.out.lasso=cv.glmnet(x_train,y_train,alpha=1)
plot(cv.out.lasso)
```

```{r}
bestlam.lasso=cv.out.lasso$lambda.min
cat("lowest lamda from CV: ", bestlam.lasso, "\n\n")
```

We see that the lowest MSE is when $\lambda$ appro = `r round(bestlam.lasso,digits=6)`. 

```{r}
lasso.pred=predict(lasso.mod,s=bestlam.lasso,newx=x_test)
#
out.lasso = glmnet(x, y, alpha = 1, lambda = grid) # Fit lasso model on full dataset
lassoMeanMse = mean((lasso.pred-y_test)^2)
cat("Mean MSE for best Lasso lamda: ", lassoMeanMse, "\n\n")
#
lasso_coef = predict(out.lasso, type = "coefficients", s = bestlam.lasso)[1:13,] # Display coefficients using λ chosen by CV
cat("\nAll the coefficients : \n")
lasso_coef
cat("\nThe non-zero coefficients : \n")
lasso_coef[lasso_coef!=0]
```
From LASSO regression, the coefficients of 11 variables are not zero, the coefficients of the remaining variables become zero. From the results, we can see that race, gender, age, population, population density and rural proportions will all have an impact on total cases.

```{r lasso R2, echo=FALSE}
sst1 <- sum((y_test - mean(y_test))^2)
sse1 <- sum((lasso.pred - y_test)^2)
rsq1 <- 1 - sse1 / sst1
```
We then calculate the R squared of lasso regression, which is `r rsq1`.  
